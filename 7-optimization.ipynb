{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_attributes = pd.read_csv('step_04/clinical_attributes.csv')\n",
    "z_score = pd.read_csv('step_04/z_score.csv')\n",
    "mutation = pd.read_csv('step_04/mutation.csv')\n",
    "response = pd.read_csv('step_04/response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = response['overall_survival'].to_numpy()\n",
    "datasets = [\n",
    "    (\"clinical\", clinical_attributes.to_numpy()),\n",
    "    (\"z_score\", z_score.to_numpy()),\n",
    "    (\"mutation\", mutation.to_numpy())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch vs HalvingGridSearch vs Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models():\n",
    "    def __init__(self, linspace_size: int = 3, n_iter_search: int = 15):\n",
    "        self.linspace_size = 3\n",
    "        self.algorithms = {\n",
    "                \"knn\": ( \n",
    "                    KNeighborsClassifier(),\n",
    "                    {\n",
    "                        \"n_neighbors\": np.linspace(3, 10, num=linspace_size, dtype=int),\n",
    "                        \"weights\": [\"uniform\", \"distance\"],\n",
    "                        \"p\": np.linspace(1, 10, num=3, dtype=int),\n",
    "                        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                        \"leaf_size\": np.linspace(10, 100, num=linspace_size, dtype=int),\n",
    "                        \"metric\": ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "                    }\n",
    "                ),\n",
    "                \"dt\": (\n",
    "                    DecisionTreeClassifier(),\n",
    "                    {\n",
    "                        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                        \"splitter\": [\"best\", \"random\"],\n",
    "                        \"max_depth\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_split\": np.linspace(2, 100, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_leaf\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "                        \"ccp_alpha\": np.linspace(0, 0.1, num=3),\n",
    "                    }\n",
    "                ),\n",
    "                \"svm\": (\n",
    "                    SVC(),\n",
    "                    {\n",
    "                        \"C\": np.linspace(0.1, 10, num=linspace_size),\n",
    "                        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                        \"degree\": np.linspace(1, 10, num=linspace_size, dtype=int),\n",
    "                        \"gamma\": [\"scale\", \"auto\"],\n",
    "                        \"coef0\": np.linspace(0, 10, num=linspace_size),\n",
    "                        \"shrinking\": [True, False],\n",
    "                        \"probability\": [True, False],\n",
    "                        \"tol\": np.linspace(0.0001, 0.01, num=linspace_size),\n",
    "                    }\n",
    "                ),\n",
    "                \"rf\": (\n",
    "                    RandomForestClassifier(),\n",
    "                    {\n",
    "                        \"n_estimators\": np.linspace(100, 500, num=linspace_size, dtype=int),\n",
    "                        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                        \"max_depth\": np.linspace(1, 100, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_split\": np.linspace(2, 10, num=linspace_size, dtype=int),\n",
    "                        \"min_samples_leaf\": np.linspace(1, 10, num=linspace_size, dtype=int),\n",
    "                        \"max_leaf_nodes\": np.linspace(10, 90, num=9, dtype=int),\n",
    "                        \"min_impurity_decrease\": np.linspace(0, 0.1, num=linspace_size),\n",
    "                        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                        \"ccp_alpha\": np.linspace(0, 0.1, num=linspace_size),\n",
    "                        \"bootstrap\": [True, False],\n",
    "                        \"oob_score\": [True, False],\n",
    "                        \"class_weight\": [\"balanced\", \"balanced_subsample\"]\n",
    "                    }\n",
    "                ),\n",
    "                \"ada\": (\n",
    "                    AdaBoostClassifier(),\n",
    "                    {\n",
    "                        \"n_estimators\": np.linspace(10, 100, num=linspace_size, dtype=int),\n",
    "                        \"learning_rate\": np.linspace(0.1, 1, num=linspace_size),\n",
    "                        \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "                    }\n",
    "                )    \n",
    "        }\n",
    "        self.n_iter_search = n_iter_search\n",
    "\n",
    "    def report(self, results, n_top: int = 3):\n",
    "        export_list = []\n",
    "        for i in range(1, n_top + 1):\n",
    "            candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "            for candidate in candidates:\n",
    "                export_list.append({\n",
    "                    \"rank\": i,\n",
    "                    \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "                    \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "                    \"params\": results[\"params\"][candidate]\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(export_list, columns=[\"rank\", \"mean_test_score\", \"std_test_score\", \"params\"])\n",
    "\n",
    "    def random_search(self, algorithm: str, seed: int = 42):\n",
    "        return RandomizedSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_iter=self.n_iter_search, random_state=seed, n_jobs=-1)\n",
    "    \n",
    "    def grid_search(self, algorithm: str):\n",
    "        return GridSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_jobs=-1)\n",
    "    \n",
    "    def halving_search(self, algorithm: str):\n",
    "        return HalvingGridSearchCV(self.algorithms[algorithm][0], self.algorithms[algorithm][1], n_jobs=-1)\n",
    "    \n",
    "    def compare_search(self, dataset: str, X: np.array, y: np.array, algorithm: str, seed: int = 42):\n",
    "        export_list = []\n",
    "        \n",
    "        print(f\"Running Grid Search with {dataset} and {algorithm}...\")\n",
    "        grid_search = self.grid_search(algorithm)\n",
    "        \n",
    "        start = time()\n",
    "        grid_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Grid Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = grid_search.cv_results_\n",
    "\n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "        \n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"grid\",\n",
    "            \"time\": time_spent,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        print(\"Running Random Search...\")\n",
    "        random_search = self.random_search(algorithm, seed)\n",
    "\n",
    "        start = time()\n",
    "        random_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Random Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = random_search.cv_results_\n",
    "\n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "\n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"random\",\n",
    "            \"time\": time_spent,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        print(\"Running Halving Grid Search...\")\n",
    "        halving_search = self.halving_search(algorithm)\n",
    "\n",
    "        start = time()\n",
    "        halving_search.fit(X, y)\n",
    "        time_spent = time() - start\n",
    "\n",
    "        print(\"Halving Grid Search took %.2f seconds\" % (time_spent))\n",
    "\n",
    "        results = halving_search.cv_results_\n",
    "        \n",
    "        candidate = np.flatnonzero(results[\"rank_test_score\"] == 1)[0]\n",
    "\n",
    "        export_list.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"type\": \"halving\",\n",
    "            \"time\": time_spent,\n",
    "            \"mean_test_score\": results[\"mean_test_score\"][candidate],\n",
    "            \"std_test_score\": results[\"std_test_score\"][candidate],\n",
    "            \"params\": results[\"params\"][candidate]\n",
    "        })\n",
    "\n",
    "        return pd.DataFrame(export_list, columns=[\"dataset\", \"type\", \"time\", \"mean_test_score\", \"std_test_score\", \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search with clinical and rf...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algorithm \u001b[38;5;129;01min\u001b[39;00m models_instance\u001b[38;5;241m.\u001b[39malgorithms\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, data \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m----> 6\u001b[0m         tmp \u001b[38;5;241m=\u001b[39m \u001b[43mmodels_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, tmp])\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 99\u001b[0m, in \u001b[0;36mModels.compare_search\u001b[0;34m(self, dataset, X, y, algorithm, seed)\u001b[0m\n\u001b[1;32m     96\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_search(algorithm)\n\u001b[1;32m     98\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 99\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid Search took \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time_spent))\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pandas-env/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_instance = Models(linspace_size=3, n_iter_search=15)\n",
    "df = pd.DataFrame(columns=[\"dataset\", \"type\", \"time\", \"mean_test_score\", \"std_test_score\", \"params\"])\n",
    "for algorithm in models_instance.algorithms.keys():\n",
    "    for name, data in datasets:\n",
    "\n",
    "        tmp = models_instance.compare_search(name, data, np.squeeze(y), \"rf\")\n",
    "\n",
    "        df = pd.concat([df, tmp])\n",
    "        break\n",
    "    break\n",
    "\n",
    "df.to_csv(\"step_07/compare_search.csv\", index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch (Should be HalvingSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running knn on clinical dataset\n",
      "RandomizedSearchCV took 0.36 seconds for 15 candidates parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25403/3377011678.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, result])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 0.69 seconds for 40 candidate parameter settings.\n",
      "Running knn on z_score dataset\n",
      "RandomizedSearchCV took 0.51 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 1.34 seconds for 40 candidate parameter settings.\n",
      "Running knn on mutation dataset\n",
      "RandomizedSearchCV took 0.55 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 1.41 seconds for 40 candidate parameter settings.\n",
      "Running dt on clinical dataset\n",
      "RandomizedSearchCV took 0.12 seconds for 15 candidates parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=15. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 0.12 seconds for 4 candidate parameter settings.\n",
      "Running dt on z_score dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=15. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 4.64 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 4.61 seconds for 4 candidate parameter settings.\n",
      "Running dt on mutation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=15. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.79 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 0.77 seconds for 4 candidate parameter settings.\n",
      "Running svm on clinical dataset\n",
      "RandomizedSearchCV took 3.26 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 4.30 seconds for 20 candidate parameter settings.\n",
      "Running svm on z_score dataset\n",
      "RandomizedSearchCV took 9.54 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 13.10 seconds for 20 candidate parameter settings.\n",
      "Running svm on mutation dataset\n",
      "RandomizedSearchCV took 11.18 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 14.53 seconds for 20 candidate parameter settings.\n",
      "Running rf on clinical dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 10 is smaller than n_iter=15. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 3.99 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 4.06 seconds for 10 candidate parameter settings.\n",
      "Running rf on z_score dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 10 is smaller than n_iter=15. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 36.35 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 35.35 seconds for 10 candidate parameter settings.\n",
      "Running rf on mutation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 10 is smaller than n_iter=15. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 7.14 seconds for 15 candidates parameter settings.\n",
      "GridSearchCV took 6.93 seconds for 10 candidate parameter settings.\n",
      "Running ada on clinical dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=15. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 0.81 seconds for 15 candidates parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 0.77 seconds for 2 candidate parameter settings.\n",
      "Running ada on z_score dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=15. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 29.68 seconds for 15 candidates parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 30.15 seconds for 2 candidate parameter settings.\n",
      "Running ada on mutation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 2 is smaller than n_iter=15. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 1.86 seconds for 15 candidates parameter settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 1.82 seconds for 2 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "model_instance = Models(linspace_size=10, n_iter_search=15)\n",
    "results = pd.DataFrame(columns=[\"dataset\",\"type\",\"rank\", \"mean_test_score\", \"std_test_score\", \"params\"])\n",
    "\n",
    "for algorithm in models_instance.algorithms.keys():\n",
    "    for name, data in datasets:\n",
    "            print(f\"Running {algorithm} on {name} dataset\")\n",
    "\n",
    "            random_search = models_instance.random_search(algorithm)\n",
    "\n",
    "            start = time()\n",
    "            random_search.fit(data, np.squeeze(y))\n",
    "\n",
    "            print(\n",
    "                \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
    "                % ((time() - start), models_instance.n_iter_search)\n",
    "            )\n",
    "\n",
    "            result = models_instance.report(random_search.cv_results_)\n",
    "            result.insert(0, \"dataset\", name)\n",
    "            result.insert(1, \"type\", \"random\")\n",
    "\n",
    "            results = pd.concat([results, result])\n",
    "            \n",
    "            grid_search = models_instance.grid_search(algorithm)\n",
    "\n",
    "            start = time()\n",
    "\n",
    "            grid_search.fit(data, np.squeeze(y))\n",
    "\n",
    "            print(\n",
    "                \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "                % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    "            )\n",
    "\n",
    "            result = models_instance.report(grid_search.cv_results_)\n",
    "            result.insert(0, \"dataset\", name)\n",
    "            result.insert(1, \"type\", \"grid\")\n",
    "\n",
    "            results = pd.concat([results, result])\n",
    "            \n",
    "\n",
    "results.to_csv(\"step_07/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teapot\n",
    "Falta ver que onda con teapot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.12.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.1 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (1.5.1)\n",
      "Collecting deap>=1.2 (from tpot)\n",
      "  Downloading deap-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting update-checker>=0.16 (from tpot)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (4.66.4)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (2.2.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from tpot) (1.4.2)\n",
      "Collecting xgboost>=1.1.0 (from tpot)\n",
      "  Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from pandas>=0.24.2->tpot) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from pandas>=0.24.2->tpot) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from pandas>=0.24.2->tpot) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from scikit-learn>=1.4.1->tpot) (3.5.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost>=1.1.0->tpot)\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.6.2)\n",
      "Downloading TPOT-0.12.2-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deap, stopit\n",
      "  Building wheel for deap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deap: filename=deap-1.4.1-cp312-cp312-linux_x86_64.whl size=105690 sha256=5dd7508574b8a52b79fefcfa6e32140435d9403a2c00b0b552f4d70ceee5ce1e\n",
      "  Stored in directory: /home/diego/.cache/pip/wheels/6c/1d/91/0a68add63bf57c3263b06b3462179d244fed0ff1dbb8d5eff0\n",
      "  Building wheel for stopit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11938 sha256=80ee0685b08a0ffc01e7438c698ab3c7b2637c4ef9e15c5c82fd1b3ee7820f6a\n",
      "  Stored in directory: /home/diego/.cache/pip/wheels/10/10/63/c3c98c9859d2aa59553536cc2ea005d3c9c39e214ab4fd614c\n",
      "Successfully built deap stopit\n",
      "Installing collected packages: stopit, nvidia-nccl-cu12, deap, xgboost, update-checker, tpot\n",
      "Successfully installed deap-1.4.1 nvidia-nccl-cu12-2.23.4 stopit-1.1.2 tpot-0.12.2 update-checker-0.18.0 xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clinical_train, X_clinical_test, y_train, y_test = train_test_split(clinical_attributes, response, test_size=0.2, random_state=seed)\n",
    "\n",
    "X_mutation_train, X_mutation_test, _, _ = train_test_split(mutation, response, test_size=0.2, random_state=seed)\n",
    "\n",
    "X_z_score_train, X_z_score_test, _, _ = train_test_split(z_score, response, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/pandas-env/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.6825396825396826\n",
      "                                                                             \n",
      "Generation 2 - Current best internal CV score: 0.6899470899470899\n",
      "                                                                             \n",
      "Generation 3 - Current best internal CV score: 0.6899470899470899\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.692063492063492\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.6962962962962963\n",
      "                                                                              \n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.4, min_samples_leaf=13, min_samples_split=7, n_estimators=100)\n",
      "0.6835443037974683\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, population_size=20, verbosity=2, random_state=42)\n",
    "tpot.fit(X_clinical_train, np.squeeze(y_train))\n",
    "print(tpot.score(X_clinical_test, np.squeeze(y_test)))\n",
    "tpot.export('step_07/tpot_clinical_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "                                                                             \n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "                                                                             \n",
      "                                                                             \n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "                                                                             \n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.8, min_samples_leaf=19, min_samples_split=5, n_estimators=100)\n",
      "0.5991561181434599\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, population_size=20, verbosity=2, random_state=42)\n",
    "tpot.fit(X_mutation_train, np.squeeze(y_train))\n",
    "print(tpot.score(X_mutation_test, np.squeeze(y_test)))\n",
    "tpot.export('step_07/tpot_mutation_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.6338624338624339\n",
      "                                                                             \n",
      "Generation 2 - Current best internal CV score: 0.6338624338624339\n",
      "                                                                             \n",
      "Generation 3 - Current best internal CV score: 0.6338624338624339\n",
      "                                                                              \n",
      "Generation 4 - Current best internal CV score: 0.6380952380952382\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.6380952380952382\n",
      "                                                                              \n",
      "Best pipeline: MLPClassifier(input_matrix, alpha=0.0001, learning_rate_init=0.001)\n",
      "0.620253164556962\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, population_size=20, verbosity=2, random_state=42)\n",
    "tpot.fit(X_z_score_train, np.squeeze(y_train))\n",
    "print(tpot.score(X_z_score_test, np.squeeze(y_test)))\n",
    "tpot.export('step_07/tpot_z_score_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
